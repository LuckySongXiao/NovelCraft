#!/usr/bin/env python3
"""
Ollamaé—®é¢˜ä¿®å¤è„šæœ¬
è‡ªåŠ¨æ£€æµ‹å’Œä¿®å¤å¸¸è§çš„Ollamaè¿æ¥å’Œæ¨¡å‹æ£€æµ‹é—®é¢˜
"""

import asyncio
import subprocess
import sys
import time
import platform
import httpx
from typing import Dict, List, Any, Optional

class OllamaFixer:
    """Ollamaé—®é¢˜ä¿®å¤å™¨"""
    
    def __init__(self):
        self.base_url = "http://localhost:11434"
        self.default_model = "mollysama/rwkv-7-g1:0.4B"
        self.system = platform.system().lower()
        
    def print_step(self, step: str, message: str):
        """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
        print(f"\nğŸ”§ [{step}] {message}")
        
    def print_success(self, message: str):
        """æ‰“å°æˆåŠŸä¿¡æ¯"""
        print(f"âœ… {message}")
        
    def print_warning(self, message: str):
        """æ‰“å°è­¦å‘Šä¿¡æ¯"""
        print(f"âš ï¸  {message}")
        
    def print_error(self, message: str):
        """æ‰“å°é”™è¯¯ä¿¡æ¯"""
        print(f"âŒ {message}")
        
    def run_command(self, command: List[str], timeout: int = 30) -> Dict[str, Any]:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            result = subprocess.run(
                command,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            return {
                "success": result.returncode == 0,
                "stdout": result.stdout.strip(),
                "stderr": result.stderr.strip(),
                "returncode": result.returncode
            }
        except subprocess.TimeoutExpired:
            return {
                "success": False,
                "stdout": "",
                "stderr": "å‘½ä»¤æ‰§è¡Œè¶…æ—¶",
                "returncode": -1
            }
        except FileNotFoundError:
            return {
                "success": False,
                "stdout": "",
                "stderr": "å‘½ä»¤ä¸å­˜åœ¨",
                "returncode": -1
            }
        except Exception as e:
            return {
                "success": False,
                "stdout": "",
                "stderr": str(e),
                "returncode": -1
            }
    
    def check_ollama_installation(self) -> bool:
        """æ£€æŸ¥Ollamaæ˜¯å¦å·²å®‰è£…"""
        self.print_step("1/6", "æ£€æŸ¥Ollamaå®‰è£…çŠ¶æ€")
        
        result = self.run_command(["ollama", "--version"])
        if result["success"]:
            self.print_success(f"Ollamaå·²å®‰è£…: {result['stdout']}")
            return True
        else:
            self.print_error("Ollamaæœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­")
            self.print_warning("è¯·è®¿é—® https://ollama.ai/ ä¸‹è½½å®‰è£…Ollama")
            return False
    
    def check_ollama_service(self) -> bool:
        """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
        self.print_step("2/6", "æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€")
        
        # æ£€æŸ¥è¿›ç¨‹
        if self.system == "windows":
            result = self.run_command(["tasklist", "/FI", "IMAGENAME eq ollama.exe"])
            service_running = "ollama.exe" in result["stdout"]
        else:
            result = self.run_command(["pgrep", "-f", "ollama"])
            service_running = result["success"] and result["stdout"]
        
        if service_running:
            self.print_success("OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ")
            return True
        else:
            self.print_warning("OllamaæœåŠ¡æœªè¿è¡Œ")
            return False
    
    def start_ollama_service(self) -> bool:
        """å¯åŠ¨OllamaæœåŠ¡"""
        self.print_step("3/6", "å¯åŠ¨OllamaæœåŠ¡")
        
        try:
            if self.system == "windows":
                # Windowsä¸‹åœ¨åå°å¯åŠ¨
                subprocess.Popen(
                    ["ollama", "serve"],
                    creationflags=subprocess.CREATE_NEW_CONSOLE
                )
            else:
                # Linux/Macä¸‹åœ¨åå°å¯åŠ¨
                subprocess.Popen(
                    ["ollama", "serve"],
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL
                )
            
            # ç­‰å¾…æœåŠ¡å¯åŠ¨
            self.print_warning("ç­‰å¾…æœåŠ¡å¯åŠ¨...")
            time.sleep(5)
            
            # éªŒè¯æœåŠ¡æ˜¯å¦å¯åŠ¨æˆåŠŸ
            if self.check_ollama_service():
                self.print_success("OllamaæœåŠ¡å¯åŠ¨æˆåŠŸ")
                return True
            else:
                self.print_error("OllamaæœåŠ¡å¯åŠ¨å¤±è´¥")
                return False
                
        except Exception as e:
            self.print_error(f"å¯åŠ¨OllamaæœåŠ¡å¤±è´¥: {e}")
            return False
    
    async def test_api_connection(self) -> bool:
        """æµ‹è¯•APIè¿æ¥"""
        self.print_step("4/6", "æµ‹è¯•APIè¿æ¥")
        
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{self.base_url}/api/tags", timeout=10.0)
                if response.status_code == 200:
                    self.print_success(f"APIè¿æ¥æ­£å¸¸ ({self.base_url})")
                    return True
                else:
                    self.print_error(f"APIå“åº”å¼‚å¸¸: {response.status_code}")
                    return False
        except httpx.ConnectError:
            self.print_error(f"æ— æ³•è¿æ¥åˆ°API ({self.base_url})")
            return False
        except httpx.TimeoutException:
            self.print_error("APIè¿æ¥è¶…æ—¶")
            return False
        except Exception as e:
            self.print_error(f"APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def check_models(self) -> List[str]:
        """æ£€æŸ¥å·²å®‰è£…çš„æ¨¡å‹"""
        self.print_step("5/6", "æ£€æŸ¥å·²å®‰è£…æ¨¡å‹")
        
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{self.base_url}/api/tags", timeout=30.0)
                if response.status_code == 200:
                    data = response.json()
                    models = [model.get("name", "") for model in data.get("models", [])]
                    
                    if models:
                        self.print_success(f"æ£€æµ‹åˆ° {len(models)} ä¸ªæ¨¡å‹:")
                        for model in models:
                            print(f"   â€¢ {model}")
                        return models
                    else:
                        self.print_warning("æœªæ£€æµ‹åˆ°ä»»ä½•æ¨¡å‹")
                        return []
                else:
                    self.print_error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {response.status_code}")
                    return []
        except Exception as e:
            self.print_error(f"æ£€æŸ¥æ¨¡å‹å¤±è´¥: {e}")
            return []
    
    def install_default_model(self) -> bool:
        """å®‰è£…é»˜è®¤æ¨¡å‹"""
        self.print_step("6/6", f"å®‰è£…é»˜è®¤æ¨¡å‹ {self.default_model}")
        
        self.print_warning("æ­£åœ¨ä¸‹è½½æ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´...")
        result = self.run_command(["ollama", "pull", self.default_model], timeout=600)  # 10åˆ†é’Ÿè¶…æ—¶
        
        if result["success"]:
            self.print_success(f"é»˜è®¤æ¨¡å‹ {self.default_model} å®‰è£…æˆåŠŸ")
            return True
        else:
            self.print_error(f"æ¨¡å‹å®‰è£…å¤±è´¥: {result['stderr']}")
            
            # å°è¯•å®‰è£…å¤‡é€‰æ¨¡å‹
            backup_models = ["llama2:7b-chat", "qwen:7b-chat", "mistral:7b"]
            for backup_model in backup_models:
                self.print_warning(f"å°è¯•å®‰è£…å¤‡é€‰æ¨¡å‹: {backup_model}")
                result = self.run_command(["ollama", "pull", backup_model], timeout=600)
                if result["success"]:
                    self.print_success(f"å¤‡é€‰æ¨¡å‹ {backup_model} å®‰è£…æˆåŠŸ")
                    return True
            
            self.print_error("æ‰€æœ‰æ¨¡å‹å®‰è£…éƒ½å¤±è´¥äº†")
            return False
    
    async def run_full_fix(self):
        """è¿è¡Œå®Œæ•´çš„ä¿®å¤æµç¨‹"""
        print("ğŸ”§ NovelCraft Ollama é—®é¢˜ä¿®å¤å·¥å…·")
        print("=" * 50)
        
        # 1. æ£€æŸ¥å®‰è£…
        if not self.check_ollama_installation():
            print("\nâŒ ä¿®å¤å¤±è´¥: Ollamaæœªå®‰è£…")
            print("è¯·å…ˆå®‰è£…Ollama: https://ollama.ai/")
            return False
        
        # 2. æ£€æŸ¥æœåŠ¡
        service_running = self.check_ollama_service()
        if not service_running:
            if not self.start_ollama_service():
                print("\nâŒ ä¿®å¤å¤±è´¥: æ— æ³•å¯åŠ¨OllamaæœåŠ¡")
                return False
        
        # 3. æµ‹è¯•è¿æ¥
        if not await self.test_api_connection():
            print("\nâŒ ä¿®å¤å¤±è´¥: APIè¿æ¥å¼‚å¸¸")
            print("è¯·æ£€æŸ¥é˜²ç«å¢™è®¾ç½®æˆ–æ‰‹åŠ¨é‡å¯OllamaæœåŠ¡")
            return False
        
        # 4. æ£€æŸ¥æ¨¡å‹
        models = await self.check_models()
        has_default = self.default_model in models
        
        # 5. å®‰è£…é»˜è®¤æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if not has_default:
            if not self.install_default_model():
                print("\nâš ï¸  è­¦å‘Š: é»˜è®¤æ¨¡å‹å®‰è£…å¤±è´¥ï¼Œä½†åŸºæœ¬åŠŸèƒ½å¯ç”¨")
        
        # æœ€ç»ˆéªŒè¯
        print("\nğŸ” æœ€ç»ˆéªŒè¯...")
        final_models = await self.check_models()
        
        if final_models:
            print("\nâœ… ä¿®å¤å®Œæˆï¼Ollamaé…ç½®æ­£å¸¸")
            print(f"   â€¢ æœåŠ¡åœ°å€: {self.base_url}")
            print(f"   â€¢ å¯ç”¨æ¨¡å‹: {len(final_models)} ä¸ª")
            if self.default_model in final_models:
                print(f"   â€¢ é»˜è®¤æ¨¡å‹: {self.default_model} âœ“")
            print("\nğŸ’¡ ç°åœ¨å¯ä»¥åœ¨NovelCraftä¸­æ­£å¸¸ä½¿ç”¨AIåŠŸèƒ½äº†")
            return True
        else:
            print("\nâš ï¸  éƒ¨åˆ†ä¿®å¤å®Œæˆï¼Œä½†æœªæ£€æµ‹åˆ°å¯ç”¨æ¨¡å‹")
            print("è¯·æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹: ollama pull llama2")
            return False

async def main():
    """ä¸»å‡½æ•°"""
    fixer = OllamaFixer()
    
    try:
        success = await fixer.run_full_fix()
        if success:
            print("\nğŸ‰ ä¿®å¤æˆåŠŸï¼")
        else:
            print("\nâŒ ä¿®å¤æœªå®Œå…¨æˆåŠŸï¼Œè¯·æŸ¥çœ‹ä¸Šè¿°å»ºè®®")
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ä¿®å¤è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ ä¿®å¤è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    asyncio.run(main())
